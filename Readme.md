# PolicyGenius RAG Bot âš–ï¸

A **production-style Retrieval-Augmented Generation (RAG)** system for answering HR policy questions **strictly from company documents**, with observability via **LangSmith** and guardrails to prevent hallucinations.

This project is designed to demonstrate **real-world RAG engineering skills** suitable for mid-to-senior ML / AI roles.

---

## ğŸš€ What This Bot Does

- Answers **only HR policy questions** using provided documents
- Refuses to answer personal, conversational, or out-of-scope queries
- Avoids hallucination by:
  - Strict prompting
  - Retrieval-first architecture
  - Zero-temperature LLM
- Provides **auditable traces** using LangSmith

---

## ğŸ§  Architecture Overview

```
User Question
     â†“
Retriever (Chroma Vector DB)
     â†“
Relevant Policy Chunks
     â†“
Strict Prompt + LLM (Groq LLaMA 3.3 70B)
     â†“
Final Answer (with citation)
```

---

## ğŸ“ Project Structure

> **Data governance note:** Raw HR policy documents inside the `data/` directory are intentionally excluded from version control to prevent accidental sharing of proprietary or confidential company information.



```
policygenius-rag/
â”‚
â”œâ”€â”€ app.py                 # Streamlit app (chat UI + RAG chain)
â”œâ”€â”€ ingest.py              # Document ingestion & vector DB builder
â”œâ”€â”€ requirements.txt       # Python dependencies
â”œâ”€â”€ README.md              # Project documentation
â”œâ”€â”€ .gitignore
â”‚
â”œâ”€â”€ data/                  # HR policy PDFs / DOCX (ignored by git)
â”œâ”€â”€ chroma_db/             # Vector database (ignored by git)
â””â”€â”€ .env                   # API keys (ignored by git)
```

---

## ğŸ” Environment Variables (`.env`)

Create a `.env` file in the root directory:

```env
GROQ_API_KEY=your_groq_api_key
LANGCHAIN_API_KEY=your_langsmith_api_key
LANGCHAIN_TRACING_V2=true
LANGCHAIN_PROJECT=policygenius-rag
```

---

## ğŸ“¦ Dependencies

See `requirements.txt`. Core libraries:

- `streamlit` â€“ UI
- `langchain` ecosystem â€“ RAG framework
- `chromadb` â€“ vector storage
- `sentence-transformers` â€“ embeddings
- `langchain-groq` â€“ LLM inference
- `python-dotenv` â€“ environment management

---

## ğŸ§¾ How to Run

### 1ï¸âƒ£ Install dependencies

```bash
pip install -r requirements.txt
```

### 2ï¸âƒ£ Add policy documents

Place PDF / DOCX files inside:

```text
data/
```

### 3ï¸âƒ£ Run the app

```bash
streamlit run app.py
```

### 4ï¸âƒ£ Index documents

Use the **Admin Sidebar â†’ Re-index Documents** button.

---

## ğŸ” Observability (LangSmith)

All RAG steps are traced:

- Retriever calls
- Prompt construction
- LLM response

You can inspect runs at:

ğŸ‘‰ https://smith.langchain.com

This allows you to **prove**:
- Which documents were retrieved
- Why a specific answer was generated
- That the model did not hallucinate

---

## ğŸ§ª Design Decisions (Interview-Ready)

- **Temperature = 0** â†’ deterministic answers
- **Strict prompt rules** â†’ no guessing, no role-play
- **Header-aware chunking** â†’ accurate section citations
- **Vector DB reset on re-ingestion** â†’ avoids stale data

---

## ğŸ›‘ Non-Goals

- Not a general chatbot
- Not trained on internal data
- No fine-tuning (pure RAG)

---

## ğŸ“Œ Future Improvements

- Hybrid Search (BM25 + Vector)
- Query classification layer
- Role-based access control
- Evaluation dataset + automated testing

---

## ğŸ‘©â€ğŸ’» Author

Built as a **portfolio-grade RAG system** to demonstrate applied LLM engineering, not a toy demo.

